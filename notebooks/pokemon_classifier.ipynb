{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea2ee86",
   "metadata": {},
   "source": [
    "# Pokemon type classifier\n",
    "\n",
    "This project takes a dataset with Pokémon sprites and trains a CNN to classify whether a Pokémon belongs to a certain type (e.g. water: true or false). It is meant as a demo to show how DVC can be used in deep learning scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0a073",
   "metadata": {},
   "source": [
    "## Imports and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04cb1f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 10:06:57.698779: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-21 10:06:57.747721: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-21 10:06:57.748870: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.layers import (Activation, BatchNormalization, Conv2D, Dense,\n",
    "                          Dropout, Flatten, MaxPooling2D)\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, classification_report,\n",
    "                             confusion_matrix, log_loss, accuracy_score, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tqdm import tqdm\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1d619",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cc5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED: int = 42\n",
    "POKEMON_TYPE_TRAIN: str = \"Water\"\n",
    "    \n",
    "SOURCE_DIRECTORY: str = \"data/external\"\n",
    "DESTINATION_DIRECTORY: str = \"data/processed\"\n",
    "TRAIN_DATA_IMAGES: str = \"images\"\n",
    "TRAIN_DATA_LABELS: str = \"stats/pokemon-gen-1-8.csv\"\n",
    "\n",
    "MODEL_TEST_SIZE: float = 0.2\n",
    "MODEL_LEARNING_RATE: float = 0.001\n",
    "MODEL_EPOCHS: int = 10\n",
    "MODEL_BATCH_SIZE: int = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11e358",
   "metadata": {},
   "source": [
    "## Util: find root of Git project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3189d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_project_root() -> Optional[Path]:\n",
    "    current = Path(\".\").resolve()\n",
    "    \n",
    "    while True:\n",
    "        if (current / \".git\").exists():\n",
    "            return current\n",
    "        \n",
    "        if current.parent == current:\n",
    "            print(\"WARNING: No .git dir found\")\n",
    "            return current\n",
    "              \n",
    "        current = current.parent\n",
    "        \n",
    "\n",
    "PROJECT_ROOT = find_project_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32843bac",
   "metadata": {},
   "source": [
    "## Make sure the right directory structure exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94350a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(PROJECT_ROOT / DESTINATION_DIRECTORY)\n",
    "except:\n",
    "    print(\"NO FOLDER\")\n",
    "    \n",
    "try:\n",
    "    os.mkdir(PROJECT_ROOT / \"outputs\")\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2367b",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ac9358",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/totoy/Desktop/get-get-aus/study/MLOps/dtc-workshop/data/external/stats/pokemon-gen-1-8.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     pokemon\u001b[39m.\u001b[39mto_csv(PROJECT_ROOT \u001b[39m/\u001b[39m DESTINATION_DIRECTORY \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpokemon.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)            \n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m(pokemon)\n\u001b[0;32m---> 25\u001b[0m pokemon \u001b[39m=\u001b[39m preprocess_training_labels(TRAIN_DATA_LABELS)\n\u001b[1;32m     26\u001b[0m pokemon\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mpreprocess_training_labels\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_training_labels\u001b[39m(dataset) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m----> 4\u001b[0m     pokemon \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(PROJECT_ROOT \u001b[39m/\u001b[39;49m SOURCE_DIRECTORY \u001b[39m/\u001b[39;49m dataset)\n\u001b[1;32m      5\u001b[0m     pokemon \u001b[39m=\u001b[39m pokemon[[\u001b[39m\"\u001b[39m\u001b[39mpokedex_number\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtype1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtype2\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Create one-hot columns for each type\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/get-get-aus/study/MLOps/dtc-workshop/.venv/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/get-get-aus/study/MLOps/dtc-workshop/.venv/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/get-get-aus/study/MLOps/dtc-workshop/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/get-get-aus/study/MLOps/dtc-workshop/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/get-get-aus/study/MLOps/dtc-workshop/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/get-get-aus/study/MLOps/dtc-workshop/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/get-get-aus/study/MLOps/dtc-workshop/.venv/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/totoy/Desktop/get-get-aus/study/MLOps/dtc-workshop/data/external/stats/pokemon-gen-1-8.csv'"
     ]
    }
   ],
   "source": [
    "# Process Pokémon and one-hot encode the types\n",
    "\n",
    "def preprocess_training_labels(dataset) -> pd.DataFrame:\n",
    "    pokemon = pd.read_csv(PROJECT_ROOT / SOURCE_DIRECTORY / dataset)\n",
    "    pokemon = pokemon[[\"pokedex_number\", \"name\", \"type1\", \"type2\"]]\n",
    "\n",
    "    # Create one-hot columns for each type\n",
    "    types = set(pokemon[\"type1\"])\n",
    "    for t in types:\n",
    "        pokemon[\"is\" + str(t).capitalize()] = 0\n",
    "\n",
    "    # Iterate over Pokémon\n",
    "    for i, p in pokemon.iterrows():\n",
    "\n",
    "        #  Set one-hot columns to 1 for relevant types\n",
    "        pokemon.loc[i, \"is\" + p[\"type1\"].capitalize()] = 1\n",
    "\n",
    "        if not pd.isna(p[\"type2\"]):\n",
    "            pokemon.loc[i, \"is\" + p[\"type2\"].capitalize()] = 1\n",
    "            \n",
    "    # Save output    \n",
    "    pokemon.to_csv(PROJECT_ROOT / DESTINATION_DIRECTORY / 'pokemon.csv', index=False)            \n",
    "    return(pokemon)\n",
    "\n",
    "pokemon = preprocess_training_labels(TRAIN_DATA_LABELS)\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image data\n",
    "\n",
    "def preprocess_training_data(dataset) -> pd.DataFrame:\n",
    "\n",
    "    data_directory_images = PROJECT_ROOT / SOURCE_DIRECTORY / dataset\n",
    "    output_directory = PROJECT_ROOT / DESTINATION_DIRECTORY / \"pokemon\"\n",
    "\n",
    "    pokemon = pd.read_csv(PROJECT_ROOT / DESTINATION_DIRECTORY / 'pokemon.csv')\n",
    "    pokemon[\"imagePath\"] = np.nan\n",
    "\n",
    "    # Remove processed folder and create empty new one\n",
    "    try:\n",
    "        shutil.rmtree(output_directory)\n",
    "        os.mkdir(output_directory)\n",
    "    except:\n",
    "        os.mkdir(output_directory)\n",
    "\n",
    "    # Copy images to processed folder\n",
    "    for image in os.listdir(data_directory_images):\n",
    "        pokemon_id = image.split('.')[0]\n",
    "\n",
    "        # Add leading zeroes to ID\n",
    "        while len(pokemon_id) < 3:\n",
    "            pokemon_id = \"0\" + pokemon_id\n",
    "\n",
    "        # Images with no variety (e.g. \"211.png\")\n",
    "        if pokemon_id.isnumeric():\n",
    "\n",
    "            # Copy to processed folder\n",
    "            src = data_directory_images / image\n",
    "            dst = os.path.join(output_directory, pokemon_id + \".png\")\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "            # Set image path in data frame\n",
    "            pokemon.loc[pokemon[\"pokedex_number\"] == int(pokemon_id), 'imagePath'] = dst\n",
    "\n",
    "    # Drop Pokemon without image path\n",
    "    pokemon = pokemon.dropna(subset=[\"imagePath\"])\n",
    "    \n",
    "    # Save pokemon.csv with image paths\n",
    "    pokemon.to_csv(PROJECT_ROOT / DESTINATION_DIRECTORY / 'pokemon-with-image-paths.csv', index=False)\n",
    "    \n",
    "    return(pokemon)\n",
    "\n",
    "\n",
    "pokemon = preprocess_training_data(TRAIN_DATA_IMAGES)\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76e7fb",
   "metadata": {},
   "source": [
    "## Load training data and create split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9587d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "def load_training_data(labels) -> np.array:\n",
    "    train_image = []\n",
    "\n",
    "    for i in tqdm(range(labels.shape[0])):\n",
    "\n",
    "        img = tf.keras.utils.load_img(labels.iloc[i][\"imagePath\"], color_mode='rgba')\n",
    "        img = tf.keras.utils.img_to_array(img)\n",
    "        img = img/255\n",
    "        train_image.append(img)\n",
    "    X = np.array(train_image)\n",
    "    \n",
    "    return(X)\n",
    "\n",
    "X = load_training_data(pokemon)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "\n",
    "def create_labels(labels):\n",
    "    return(pokemon[[\"is\" + POKEMON_TYPE_TRAIN]])\n",
    "\n",
    "y = create_labels(pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=SEED, test_size=MODEL_TEST_SIZE, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train and test data\n",
    "\n",
    "pickle.dump(X, open(PROJECT_ROOT / DESTINATION_DIRECTORY / \"X.pckl\", \"wb\"))\n",
    "pickle.dump(X_train, open(PROJECT_ROOT / DESTINATION_DIRECTORY / \"X_train.pckl\", \"wb\"))\n",
    "pickle.dump(X_test, open(PROJECT_ROOT / DESTINATION_DIRECTORY / \"X_test.pckl\", \"wb\"))\n",
    "\n",
    "pickle.dump(y, open(PROJECT_ROOT / DESTINATION_DIRECTORY / \"y.pckl\", \"wb\"))\n",
    "pickle.dump(y_train, open(PROJECT_ROOT / DESTINATION_DIRECTORY / \"y_train.pckl\", \"wb\"))\n",
    "pickle.dump(y_test, open(PROJECT_ROOT / DESTINATION_DIRECTORY / \"y_test.pckl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36cbb4",
   "metadata": {},
   "source": [
    "## Define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model_image_size_x, model_image_size_y):\n",
    "    img_input = layers.Input(shape=(model_image_size_x, model_image_size_y, 4))\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, kernel_size=(5,5), activation='relu', kernel_regularizer=regularizers.l2(l=0.01), input_shape=(model_image_size_x, model_image_size_y, 4)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(4, kernel_size=(5,5), activation='relu', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Legacy needed for M1/M2\n",
    "    optimizer = keras.optimizers.legacy.Adam(learning_rate=0.001) #Adam, RMSprop or SGD\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy'\n",
    "        , optimizer=optimizer\n",
    "        , metrics=[keras.metrics.AUC()]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return(model)\n",
    "\n",
    "model_image_size_x = len(X[1])\n",
    "model_image_size_y = len(X[2])\n",
    "\n",
    "model = compile_model(model_image_size_x, model_image_size_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model\n",
    "\n",
    "def train_estimator(model):\n",
    "    def calculate_class_weights(y_train):\n",
    "        ratio_true = sum(y_train[\"is\" + POKEMON_TYPE_TRAIN] == 1) / len(y_train[\"is\" + POKEMON_TYPE_TRAIN])\n",
    "        ratio_false = sum(y_train[\"is\" + POKEMON_TYPE_TRAIN] != 1) / len(y_train[\"is\" + POKEMON_TYPE_TRAIN])\n",
    "\n",
    "        return {0: ratio_true, 1: ratio_false}\n",
    "\n",
    "\n",
    "    estimator = model.fit(X_train, y_train, \n",
    "                        validation_data=(X_test, y_test),\n",
    "                        class_weight= calculate_class_weights(y_train),\n",
    "                        epochs=MODEL_EPOCHS, \n",
    "                        batch_size=MODEL_BATCH_SIZE,\n",
    "                        verbose=1)\n",
    "\n",
    "    return(estimator)\n",
    "\n",
    "estimator = train_estimator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a467747",
   "metadata": {},
   "source": [
    "## Plot training history and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a250ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator):\n",
    "    # Training history\n",
    "    plt.figure()\n",
    "    plt.ylabel('Loss / Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "\n",
    "    for k in estimator.history.keys():\n",
    "        plt.plot(estimator.history[k], label = k) \n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(PROJECT_ROOT / \"outputs\" / \"train_history.png\", dpi=150, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    # Save model itself\n",
    "    model.save(PROJECT_ROOT / \"outputs\" / \"model\")\n",
    "    \n",
    "save_estimator(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3c9a0",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db46774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on one Pokémon\n",
    "def predict_pokemon(id: str, verbose=0):\n",
    "    \n",
    "    id = id.zfill(3)\n",
    "    \n",
    "    img = tf.keras.utils.load_img(PROJECT_ROOT/DESTINATION_DIRECTORY/'pokemon'/f'{id}.png', color_mode='rgba')\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "    img = img/255\n",
    "\n",
    "\n",
    "    classes = y\n",
    "    proba = model.predict(img.reshape(1,475,475,4), verbose=verbose)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    return proba[0][0]\n",
    "\n",
    "print(predict_pokemon(\"258\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model(PROJECT_ROOT / \"outputs\" / \"model\")\n",
    "\n",
    "# Load data\n",
    "X = pickle.loads((PROJECT_ROOT / DESTINATION_DIRECTORY / \"X.pckl\").read_bytes())\n",
    "X_train = pickle.loads((PROJECT_ROOT / DESTINATION_DIRECTORY / \"X_train.pckl\").read_bytes())\n",
    "X_test = pickle.loads((PROJECT_ROOT / DESTINATION_DIRECTORY / \"X_test.pckl\").read_bytes())\n",
    "\n",
    "y = pickle.loads((PROJECT_ROOT / DESTINATION_DIRECTORY / \"y.pckl\").read_bytes())\n",
    "y_train = pickle.loads((PROJECT_ROOT / DESTINATION_DIRECTORY / \"y_train.pckl\").read_bytes())\n",
    "y_test = pickle.loads((PROJECT_ROOT / DESTINATION_DIRECTORY / \"y_test.pckl\").read_bytes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87081b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all Pokémon\n",
    "predictions = model.predict(X) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d30b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = {}\n",
    "\n",
    "metrics[\"acc\"] = float(accuracy_score(y, predictions))\n",
    "metrics[\"precision\"] = float(precision_score(y, predictions))\n",
    "metrics[\"recall\"] = float(recall_score(y, predictions))\n",
    "metrics[\"f1\"] = float(f1_score(y, predictions))\n",
    "\n",
    "# Save metrics\n",
    "with open(PROJECT_ROOT / \"outputs\" / \"metrics.yaml\", 'w') as file:\n",
    "    yaml.dump(metrics, file, default_flow_style=False)\n",
    "    \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a78d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y, predictions)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "# Save confusion matrix\n",
    "plt.savefig(PROJECT_ROOT / \"outputs\" / \"confusion_matrix.png\", dpi=150, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960acc1",
   "metadata": {},
   "source": [
    "*Attribution*:\n",
    "\n",
    "- https://github.com/benckx/dnn-movie-posters\n",
    "- https://medium.com/m2mtechconnect/classifying-pok%C3%A9mon-images-with-machine-learning-79b9bc07c080\n",
    "- https://www.kaggle.com/datasets/rounakbanik/pokemon"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "adfa5400c33c3eb8ae0d2dbb26097a67da7859b6917822b382ea60a42be13f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
